{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ee9cf6",
   "metadata": {},
   "source": [
    "# Dog Breed Identification — Transfer Learning (VGG19)\n",
    "\n",
    "This notebook demonstrates end-to-end steps: dataset download (Oxford-IIIT Pet), preprocessing, transfer learning with VGG19, training, evaluation, Grad-CAM explainability, saving the model, and a Flask inference wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd691ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# 1) Environment setup & imports\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tfimport os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print('TF version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87773514",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 2) Reproducibility & GPU check\u001b[39;00m\n\u001b[32m      2\u001b[39m SEED = \u001b[32m42\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mnp\u001b[49m.random.seed(SEED)\n\u001b[32m      4\u001b[39m random.seed(SEED)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# tf.random.set_seed(SEED)  # uncomment if needed\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# 2) Reproducibility & GPU check\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)  # uncomment if needed\n",
    "\n",
    "print('GPUs:', tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Download & prepare dataset (Oxford-IIIT Pet via tfds)\n",
    "# We'll use tensorflow_datasets for a demo and prepare train/val/test splits as image datasets.\n",
    "dataset_name = 'oxford_iiit_pet'\n",
    "(ds_all, ds_info) = tfds.load(dataset_name, split='train+test', with_info=True, as_supervised=True)\n",
    "print('Dataset info:', ds_info)\n",
    "\n",
    "NUM_CLASSES = ds_info.features['label'].num_classes\n",
    "print('Num classes (labels):', NUM_CLASSES)\n",
    "\n",
    "# Convert to tf.data.Dataset with (image, label) pairs and simple preprocessing later in generators/cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83fe20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Quick data inspection: show samples and class distribution\n",
    "import math\n",
    "\n",
    "sample_images = []\n",
    "count = 0\n",
    "for image, label in tfds.as_numpy(ds_all):\n",
    "    sample_images.append((image, label))\n",
    "    count += 1\n",
    "    if count >= 12:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, (img, lbl) in enumerate(sample_images):\n",
    "    ax = plt.subplot(3,4,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(int(lbl))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Sample images (labels shown as integers)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Data preprocessing & augmentation (ImageDataGenerator compatible with VGG19)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# For demo we'll show how to use flow_from_directory later when you have folders organized.\n",
    "print('Prepared ImageDataGenerator for augmentation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Create train/validation generators (example assumes directory layout)\n",
    "# If you prepared `data/train` and `data/validation` use the following pattern:\n",
    "# train_generator = train_gen.flow_from_directory('data/train', target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='sparse')\n",
    "# val_generator = train_gen.flow_from_directory('data/validation', target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='sparse')\n",
    "\n",
    "print('When using local folders: use flow_from_directory to create generators with class indices mapping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Build transfer-learning model with VGG19 base\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "x = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Add classification head & compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3')]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Training — top-layer training (fit with callbacks)\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('models/dogbreed_best.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "]\n",
    "\n",
    "# NOTE: Replace the following placeholders with your actual generators or tf.data datasets.\n",
    "# history = model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=callbacks)\n",
    "\n",
    "print('Run training using `model.fit(...)` with your prepared generators. Example in models/train.py.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f04dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Fine-tuning (unfreeze last VGG blocks + continue training)\n",
    "# Example: unfreeze from block5\n",
    "for layer in base_model.layers:\n",
    "    if 'block5' in layer.name:\n",
    "        layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(..., epochs=5, callbacks=callbacks)\n",
    "print('Unfroze block5 for fine-tuning; recompile with lower LR and continue training.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Evaluation: evaluate on test dataset and compute confusion matrix\n",
    "# Example placeholders (run after you have a trained model & test_generator)\n",
    "# test_loss, test_acc = model.evaluate(test_generator)\n",
    "# print('Test accuracy:', test_acc)\n",
    "\n",
    "# Compute per-class metrics and confusion matrix using sklearn when you have y_true and y_pred arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Prediction examples for scenarios\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image_pill(img_path, model, class_names, top_k=3):\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    x = image.img_to_array(img)/255.0\n",
    "    x = np.expand_dims(x, 0)\n",
    "    preds = model.predict(x)[0]\n",
    "    idx = np.argsort(preds)[::-1][:top_k]\n",
    "    return [(class_names[i], float(preds[i])) for i in idx]\n",
    "\n",
    "# Example usage (after training and saving labels):\n",
    "# class_names = open('models/labels.txt').read().splitlines()\n",
    "# print(predict_image_pill('some.jpg', model, class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1941709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Explainability: Grad-CAM visualization (simple implementation)\n",
    "import cv2\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Usage: resize heatmap and overlay on original image for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Save & export model (.h5 and SavedModel)\n",
    "# model.save('models/dogbreed.h5')\n",
    "# model.save('models/saved_model')\n",
    "\n",
    "# Optional: convert to TFLite\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "# open('models/dogbreed.tflite','wb').write(tflite_model)\n",
    "print('Use model.save(...) to write HDF5/SavedModel formats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) Flask inference wrapper: predict_image(file)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image_file(img_path, model, labels, target_size=(224,224), top_k=3):\n",
    "    img = Image.open(img_path).convert('RGB').resize(target_size)\n",
    "    x = np.array(img)/255.0\n",
    "    x = np.expand_dims(x, 0)\n",
    "    preds = model.predict(x)[0]\n",
    "    idx = np.argsort(preds)[::-1][:top_k]\n",
    "    return [(labels[i], float(preds[i])) for i in idx]\n",
    "\n",
    "print('Helper for Flask inference ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) Local Flask app demo & request tests (example)\n",
    "# Example curl / requests usage to test the running Flask server\n",
    "# curl -F \"file=@/path/to/dog.jpg\" http://127.0.0.1:5000/predict\n",
    "\n",
    "# Example python requests test\n",
    "# import requests\n",
    "# r = requests.post('http://127.0.0.1:5000/predict', files={'file': open('dog.jpg','rb')})\n",
    "# print(r.status_code, r.text)\n",
    "print('See app.py in the repository for the full Flask demo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae207e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17) Unit tests for pipeline & prediction functions (pytest examples)\n",
    "# Save this as tests/test_pipeline.py when ready\n",
    "#\n",
    "# def test_preprocess_shape():\n",
    "#     img = Image.new('RGB', (300,300), color='white')\n",
    "#     img.save('tmp.jpg')\n",
    "#     out = predict_image_file('tmp.jpg', model, ['cls0'])\n",
    "#     assert isinstance(out, list)\n",
    "#\n",
    "print('Add pytest tests under tests/ to validate preprocessing, generators and Flask endpoints.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ready — follow cells to train and export your model.\n"
     ]
    }
   ],
   "source": [
    "# 18) Helper utilities & wrap-up\n",
    "# Plot training history utility\n",
    "\n",
    "def plot_history(history):\n",
    "    if history is None:\n",
    "        return\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history.get('val_loss', []), label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history.get('accuracy', []), label='acc')\n",
    "    plt.plot(history.history.get('val_accuracy', []), label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "print('Notebook ready — follow cells to train and export your model.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
